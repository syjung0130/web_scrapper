{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Crawling\n",
    "페이지 하나만 분석하는 것은 스크레이퍼라고 부르고 여러 페이지, 여러 사이트를 이동하는 스크레이퍼를 크롤러라고 부른다.\n",
    "웹크롤러라는 이름은 이름 그대로 웹을 크롤링한다는 의미.. 특정 URL에서 페이지를 가져오고, 그 페이지를 검사해서 다른 URL을 찾고, 다시 그 페이지를 가져오는 작업을 반복한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 단일 도메인 내의 이동\n",
    "임의의 위키백과 페이지를 가져와서 페이지의 링크 목록을 가져오는 코드를 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib2 import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen(\"https://en.wikipedia.org/wiki/Kevin_Bacon\")\n",
    "bsObj = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "for link in bsObj.findAll(\"a\"):\n",
    "    if 'href' in link.attrs:\n",
    "        print(link.attrs['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 링크에는 '항목링크'와 '항목링크가 아닌 다른 링크'들이 섞여있다.\n",
    "항목링크가 다른 링크들과 구분되고 항목링크들만이 가진 공통점으로 아래 세가지가 있다.\n",
    " - 이 링크들은 id가 bodyContent인 div안에 있다.\n",
    " - URL에는 세미콜론이 포함되어있지 않다.\n",
    " - URL은 /wiki/로 시작한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib2 import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "html = urlopen(\"https://en.wikipedia.org/wiki/Kevin_Bacon\")\n",
    "bsObj = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "for link in bsObj.find(\"div\", {\"id\":\"bodyContent\"}).findAll(\"a\", href=re.compile(\"^(/wiki/)((?!:).)*$\")):\n",
    "    if 'href' in link.attrs:\n",
    "        print(link.attrs['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 예제는 \"https://en.wikipedia.org/wiki/Kevin_Bacon\" 페이지의 항목링크들을 저장한 뒤에 각 링크들의 항목링크들을 출력하는 예제이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib2 import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import random\n",
    "import re\n",
    "\n",
    "random.seed(datetime.datetime.now())\n",
    "\n",
    "def getLinks(articleUrl):\n",
    "    html = urlopen(\"https://en.wikipedia.org\"+articleUrl)\n",
    "    bsObj = BeautifulSoup(html, \"html.parser\")\n",
    "    return bsObj.find(\"div\", {\"id\":\"bodyContent\"}).findAll(\"a\", href=re.compile(\"^(/wiki/)((?!:).)*$\"))\n",
    "\n",
    "links = getLinks(\"/wiki/Kevin_Bacon\")\n",
    "print('@@@@ links type: {0}'.format(type(links)))\n",
    "while len(links) > 0:\n",
    "    newArticle = links[random.randint(0, len(links)-1)].attrs[\"href\"]\n",
    "    print(newArticle)\n",
    "    links = getLinks(newArticle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscraping",
   "language": "python",
   "name": "webscraping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
